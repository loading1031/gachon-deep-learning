### 책
1. 267p(?), 273p, 298p, 302p, 305p, 309p, 375p, 392p, 403p, 404p, 405p,408p, 411p, 
2. Manifold: 많이 접어서 고차원이된 데이터를 의미 -> 고차원의 데이터는 데이터 특징을 파악하기 힘듦. 
   고차원의 데이터를 다시 펴서(저차원으로 만들어) 특징을 알기 쉽게 함.
3. t-sne
4. gradient-vanishing문제가 있기 때문에 딥러닝 구조를 복잡하면 안좋음 -> ResNet을 이용해 극복함.

### 1권 키워드
1. 머신러닝과 딥러닝의 차이점
2. 차원 축소, 차원 선택
3. 자가진도 학습
4. 마스킹 학습
5. 오버피팅 vs 언더피팅
6. cross-validation 하는 이유
7. mse 수식
8. categorical / binary cross-entropy
9. F&Q에 있는건 다 나옴
10. k-fold learning, manifold learning
11. 정밀도, 재현율, f1, accuracy, 혼동행렬
12. 경사하강법
13. 배치/확률/미니배치 (192? 196?)
14. 앙상블이 뭔지

### 2권
1. 커스텀 레이어 : 503p~504p, 511p
2. 605p
3. 13장은 거의 스킵
4. 14장 시장 ~ 597p까지 
5. RNN : 640p 
6. LSTM: 675p
7. GRU: 678p
8. time-split-sequence
9. RNN 회귀는 레이블이 없어서 상관없음. 
10. RNN 분류의 경우, window로 잡은 입력값의 레이블이 서로 다를 수가 있음
이럴 때는 1. `더 많이 나온 레이블을 기준으로` 2. `문제에 따라서` 결정해야함


임베딩종류
1. 원핫인코딩
2. 숫자 인코딩
3. 텍스트 임베딩