## cnn_classification
> 의문) 분류에서 loss그래프가 2.0에서 1.92까지 떨어지거든?   
그런데, accuracy는 0.255에서 0.285로 상승했어.   
> 로스는 저렇게 작은데 왜 accuracy 향상이 작지?

> 답변) Loss가 큰 폭으로 줄어들지만, Accuracy가 비교적 작게 향상되는 경우는 일반적이며, 그 이유는 아래와 같습니다.
```
1. Loss는 확률적 예측의 개선을 반영:
Loss 함수(예: Entropy)는 모델의 확률 분포가 실제 정답과 얼마나 가까운지를 측정합니다.   
모델이 각 클래스에 대해 확률을 더 정확하게 예측할수록 Loss가 줄어듭니다.

Loss가 줄어든다는 것은 모델이 정답 클래스에 더 높은 확률을 할당하고 있음을 의미하지만,  
이러한 개선이 반드시 Accuracy에 큰 영향을 주지는 않습니다.

예를 들어, 모델이 0.7의 확률을 정답 클래스에 할당했다가 0.9로 확률을 높였다면 Loss는 크게 줄어들 수 있지만, 
Accuracy에는 변화가 없을 수 있습니다. (이미 정답을 맞췄기 때문)

2. Accuracy는 이진적인 측정:
Accuracy는 각 예측이 정답인지 아닌지만 평가합니다. 
예측이 정답 클래스로 분류되기만 하면, 확률 값이 0.51이든 0.99이든 동일한 정확한 예측으로 간주됩니다.

즉, 확률값이 정답에 더 가깝게 개선되더라도, 만약 이미 그 예측이 정확하다면 Accuracy에 영향을 크게 미치지 않습니다.
반대로, 아주 소수의 예측이 바뀌어서 정답을 맞히게 되면, Accuracy는 아주 작은 상승만 있을 수 있습니다.

3. 데이터 불균형 또는 클래스 분포 문제:
만약 클래스 간 불균형이 있다면, 일부 클래스에 대한 예측이 개선되어도 전체적인 Accuracy 향상은 크지 않을 수 있습니다.
특히, 소수 클래스에 대한 예측 성능이 개선되더라도 Accuracy 전체에 큰 영향을 미치지 않을 수 있습니다.

4. Accuracy의 낮은 민감도:
Accuracy는 특정 구간에서 민감도가 낮을 수 있습니다.
예를 들어, 모델이 학습 초기 단계에서 확률이 조금씩 개선되어 Loss가 빠르게 감소할 수 있지만,
Accuracy는 천천히 상승할 수 있습니다. 이는 정확하게 분류되는 샘플의 비율이 크게 변화하지 않기 때문입니다.

5. Accuracy 향상에 기여하는 샘플 수:
Loss 감소는 모든 샘플에 대해 개선될 수 있지만,
Accuracy 향상은 주로 정답을 맞히지 못하던 샘플에 대해서만 개선됩니다.
즉, 모델이 더 많은 샘플을 정확하게 분류해야 Accuracy가 눈에 띄게 상승할 수 있습니다.

6. 모델의 초기 상태:
초기 학습 단계에서는 모델의 정확도가 낮아도 Loss는 급격하게 줄어들 수 있습니다.
이는 모델이 클래스 간 확률 차이를 개선하지만, 아직 분류 자체가 크게 향상되지 않았음을 의미합니다.
```

## LSTM vs CNN 총평
rings 분류 : CNN 승 (accuracy: 0.04 %p 더 높음)
rings 회귀 : LSTM 승 (mse: 동급, mae: 대체로 더 낮음)